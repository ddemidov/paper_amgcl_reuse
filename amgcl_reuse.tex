\documentclass[
11pt,%
tightenlines,%
twoside,%
onecolumn,%
nofloats,%
nobibnotes,%
nofootinbib,%
superscriptaddress,%
noshowpacs,%
centertags]%
{revtex4}

\usepackage{ljm}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{cleveref}
\usepackage{tabularx}

\newcolumntype{Y}{>{\raggedleft\arraybackslash}X}

\begin{document}

\title{Efficient Solution of Non-Steady State Problems with Partial Reuse of
AMG Hierarchy}
\author{\firstname{D.E.}~\surname{Demidov}}
\affiliation{
    Kazan Branch of Joint Supercomputer Center, Scientific Research Institute of System Analysis,
    the Russian Academy of Sciences; 2/31, Lobachevskii str., Kazan 420111 Russia}

\begin{abstract}
Abstract
\end{abstract}

\subclass{35-04, 65-04, 65Y05, 65Y10, 65Y15, 97N80}
\keywords{AMG, partial reuse, non-steady state.}

\maketitle

\section{Introduction}

Most of the numerical simulation problems today involve solution of large
sparse linear systems obtained from discretization of partial differential
equations on either structured or unstructured meshes. The combination of a
Krylov subspace method with algebraic multigrid (AMG) as a preconditioner is
considered to be one the most effective choices for solution of such
systems~\cite{brandt1985algebraic,ruge1987algebraic,Trottenberg2001}. One
disadvantage of the AMG preconditioner is the high cost of its setup. Depending
on the convergence rate of the iterative solution, it may take more than 50\%
of the total compute time. The cost is unavoidable when a steady state problem
is being solved, but it could be amortized for non-steady state problems either
by reusing the complete preconditioner on new time steps, or by partial updates
to the preconditioner using the new system matrix.

Reusing the full preconditioner may work when the system matrix changes slowly
over the time. In this case there is a strong chance that a preconditioner
constructed for a specific time step will act as a reasonably good
preconditioner for a couple of subsequent time steps. However, the deteriorated
quality of the preconditioner may result in a convergence rate that is bad
enough to neglect any time savings obtained by reusing the preconditioner. It
was shown in~\cite{Demidov2012} that this strategy may only be beneficial when
the solution phase is comparable to or is cheaper than the setup phase (for
example, when the solution phase is accelerated by using a GPU).

This paper considers the effects of partial reuse of AMG strategy for solution
of non-steady state problems on the example of the open-source AMGCL
library~\cite{Demidov2019, Demidov2020}.

\section{Partial reuse of AMG hierarchy}

In order to describe the proposed approach to cost reduction in AMG setup
This section describes the proposed approach to cost reduction in the setup
phase of the AMG algorithm for non-steady state problems. First, consider the
basic principles behind the AMG~\cite{brandt1985algebraic, Stuben1999}. The
method solves a system of linear algebraic equations
\begin{equation} \label{eq:auf}
    Au = f,
\end{equation}
where $A$ is a square matrix. Mutigrid methods are based on recursive
application of a two-grid scheme, which combines \emph{relaxation} and
\emph{coarse grid correction}. Relaxation, or smoothing iteration $S$, is a
simple iterative method, such as a damped Jacobi or a Gauss--Seidel
iteration~\cite{barrett1994templates}. Coarse grid correction solves the
residual equation on a coarser grid, and improves the fine-grid approximation
with the interpolated coarse-grid solution. Transfer between grids is described
with \emph{transfer operators} $P$ (\emph{prolongation} or
\emph{interpolation}) and $R$ (\emph{restriction}).

In geometric multigrid methods the matrices $A_i$ and operators $P_i$ and $R_i$
are usually supplied by the user based on the problem geometry. In algebraic
multigrid methods the grid hierarchy and the transfer operators are in general
constructed automatically, based only on the algebraic properties of the
matrix~$A$. The \emph{setup} phase of a generic AMG algorithm may be described
as follows:
\begin{algorithm}[H]
\caption{AMG setup}
\begin{algorithmic} \label{alg:setup}
    \STATE Start with a system matrix $A_1 \leftarrow A$.
    \WHILE{the matrix $A_i$ is too big to be solved directly}
        \STATE Introduce prolongation operator $P_i$ and restriction
            operator $R_i$.
        \STATE Construct the coarse system using Galerkin operator: $A_{i+1}
            \leftarrow R_i A_i P_i$.
        \STATE Construct the smoother $S_i$.
    \ENDWHILE
    \STATE Construct a direct solver for the coarsest system $A_L$.
\end{algorithmic}
\end{algorithm}

Note that in order to construct the next level in the AMG hierarchy, one only
needs to define transfer operators $P$ and $R$. Also, a common choice for the
restriction operator $R$ is a transpose of the prolongation operator: $R=P^T$.
In general, the prolongation and restriction operators depend not only on the
non-zero pattern of the system matrix, but also on its specific values.

\section{Numerical experiments}

\begin{table}
    \caption{Relative cost of the setup operations from \Cref{alg:setup}}
    \centering
    \begin{tabular}{l|rr}
        Step & Small system & Large system \\
        \hline
        Transfer operators $P_i$ and $R_i$        & 48\% & 18\% \\
        Galerkin operator $A_{i+1} = R_i A_i P_i$ & 29\% & 22\% \\
        Smoother $S_i$                            &  3\% & 18\% \\
        Direct solver for the coarsest system     &  1\% &  4\% \\
    \end{tabular}
\end{table}

\begin{table}
    \caption{Cost savings for different reuse strategies}
    \centering
    \begin{tabularx}{\textwidth}{l|YYYYYY}
        Strategy & Setup (s) & Solve (s) & Rebuilds & Iterations & Total \newline speedup (\%) & Setup \newline speedup (\%) \\ 
        \hline
        & \multicolumn{6}{c}{Convection, OpenMP} \\
        No reuse      & 1.145 & 2.780 & 49 & 5.0 &      &         \\
        Full reuse    & 0.026 & 3.186 & 1  & 5.5 & 22\% & 4~303\% \\
        Partial reuse & 0.703 & 2.769 & 5  & 5.0 & 13\% & 63\%    \\
        \hline
        & \multicolumn{6}{c}{Convection, CUDA} \\
        No reuse      & 1.890 & 0.781 & 49 & 5.0 &       &         \\
        Full reuse    & 0.039 & 0.897 & 1  & 5.5 & 185\% & 4~746\% \\
        Partial reuse & 1.284 & 0.781 & 5  & 5.0 & 29\%  & 47\%    \\
        \hline
        & \multicolumn{6}{c}{Redistancing, OpenMP} \\
        No reuse      & 1.246 & 9.508  & 49 & 15.7 &      &       \\
        Full reuse    & 0.245 & 11.324 & 9  & 18.1 & -7\% & 408\% \\
        Partial reuse & 0.749 & 9.308  & 5  & 15.6 & 7\%  & 66\%  \\
        \hline
        & \multicolumn{6}{c}{Redistancing, CUDA} \\
        No reuse      & 1.904 & 2.636 & 49 & 15.7 &      &       \\
        Full reuse    & 0.355 & 3.049 & 9  & 18.0 & 33\% & 436\% \\
        Partial reuse & 1.340 & 2.613 & 5  & 15.6 & 15\% & 42\%  \\
        \hline
        & \multicolumn{6}{c}{Navier-Stokes, OpenMP} \\
        No reuse      & 9.735 & 66.693  & 49 & 15.4 &       &       \\
        Full reuse    & 4.863 & 247.403 & 25 & 46.1 & -70\% & 100\% \\
        Partial reuse & 7.892 & 68.101  & 5  & 15.6 & 1\%   & 23\%  \\
        \hline
        & \multicolumn{6}{c}{Navier-Stokes, CUDA} \\
        No reuse      & 15.417 & 20.367 & 49 & 15.4 &       &      \\
        Full reuse    & 7.751  & 60.638 & 25 & 45.9 & -48\% & 99\% \\
        Partial reuse & 13.056 & 20.498 & 5  & 15.6 & 7\%   & 18\% \\
    \end{tabularx}
\end{table}

\section{Conclusion}

\bibliographystyle{spmpsci}
\bibliography{ref}	

\end{document}

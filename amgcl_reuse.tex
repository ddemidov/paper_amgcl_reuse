\documentclass[
11pt,%
tightenlines,%
twoside,%
onecolumn,%
nofloats,%
nobibnotes,%
nofootinbib,%
superscriptaddress,%
noshowpacs,%
centertags]%
{revtex4}

\usepackage{ljm}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{cleveref}
\usepackage{tabularx}

\newcolumntype{Y}{>{\raggedleft\arraybackslash}X}

\begin{document}

\title{Reusing AMG Hierarchy for Solution of Non-Steady State Problems}
\author{\firstname{D.~E.}~\surname{Demidov}}
\affiliation{
    Kazan Branch of Joint Supercomputer Center, Scientific Research Institute of System Analysis,
    the Russian Academy of Sciences; 2/31, Lobachevskii str., Kazan 420111 Russia}

\begin{abstract}
Abstract
\end{abstract}

\subclass{35-04, 65-04, 65Y05, 65Y10, 65Y15, 97N80}
\keywords{AMG, partial reuse, non-steady state.}

\maketitle

\section{Introduction}

Most of the numerical simulation problems today involve solution of large
sparse linear systems obtained from discretization of partial differential
equations on either structured or unstructured meshes. The combination of a
Krylov subspace method with algebraic multigrid (AMG) as a preconditioner is
considered to be one the most effective choices for solution of such
systems~\cite{brandt1985algebraic,ruge1987algebraic,Trottenberg2001}. One
disadvantage of the AMG preconditioner is the high cost of its setup. Depending
on the convergence rate of the iterative solution, the setup may take more than
50\% of the total compute time. This cost is unavoidable when a steady state
problem is being solved, but it could be amortized for non-steady state
problems either by reusing the complete preconditioner on new time steps, or by
partial updates to the preconditioner using the new system matrix.

In this paper two possible strategies of amortizing the cost of the AMG setup
are considered. The first one is the \emph{full reuse} strategy, described
in~\cite{Demidov2012}, where the AMG preconditioner is used completely
unaltered for as long as the solution is able to converge in a reasonable
number of iterations.  Reusing the preconditioner this way may work when the
system matrix changes slowly over the time. In this case there is a strong
chance that a preconditioner constructed for a specific time step will act as a
reasonably good preconditioner for a couple of subsequent time steps. However,
the applicability of the preconditioner may deteriorate with time and may
result in a convergence rate that is bad enough to neglect any time savings due
to reusing the preconditioner. It was shown in~\cite{Demidov2012} that this
strategy is mostly beneficial when the solution phase is comparable to or is
cheaper than the setup phase. This may be the case when the solution phase is
accelerated by using a GPU, or when just a couple of iterations are required
for the solution to converge.

The second approach considered here is the \emph{partial reuse} strategy, which
was recently implemented in the opensource AMGCL library~\cite{Demidov2019,
Demidov2020}. Here, the AMG hierarchy is partially updated on each of the time
steps. Namely, the transfer operators (restriction and interpolation) are
reused for a number of time steps, while the system matrices and the smoother
operators on each level of the hierarchy are updated on every step.  It is
shown that the partial reuse strategy is able to consistently reduce both the
setup cost and the overall compute time, while the full reuse strategy may be
either more efficient or counterproductive, depending on the problem that is
being solved.

The rest of the paper is structured as follows: \ldots

\section{Reusing of AMG hierarchy}

In order to describe the proposed approach to cost reduction in AMG setup
This section describes the proposed approach to cost reduction in the setup
phase of the AMG algorithm for non-steady state problems. First, consider the
basic principles behind the AMG~\cite{brandt1985algebraic, Stuben1999}. The
method solves a system of linear algebraic equations
\begin{equation} \label{eq:auf}
    Au = f,
\end{equation}
where $A$ is a square matrix. Mutigrid methods are based on recursive
application of a two-grid scheme, which combines \emph{relaxation} and
\emph{coarse grid correction}. Relaxation, or smoothing iteration $S$, is a
simple iterative method, such as a damped Jacobi or a Gauss--Seidel
iteration~\cite{barrett1994templates}. Coarse grid correction solves the
residual equation on a coarser grid, and improves the fine-grid approximation
with the interpolated coarse-grid solution. Transfer between grids is described
with \emph{transfer operators} $P$ (\emph{prolongation} or
\emph{interpolation}) and $R$ (\emph{restriction}).

In geometric multigrid methods the matrices $A_i$ and operators $P_i$ and $R_i$
are usually supplied by the user based on the problem geometry. In algebraic
multigrid methods the grid hierarchy and the transfer operators are in general
constructed automatically, based only on the algebraic properties of the
matrix~$A$. \Cref{alg:setup} describes the \emph{setup} phase of a generic AMG
method.

\begin{algorithm}
    \caption{AMG setup}
    \begin{algorithmic}[1] \label{alg:setup}
        \STATE Start with a system matrix $A_1 \leftarrow A$.
        \WHILE{the matrix $A_i$ is too big to be solved directly}
            \STATE Introduce prolongation operator $P_i$ and restriction
                operator $R_i$.
            \STATE Construct the coarse system using Galerkin operator: $A_{i+1}
                \leftarrow R_i A_i P_i$.
            \STATE Construct the smoother $S_i$.
        \ENDWHILE
        \STATE Construct a direct solver for the coarsest system $A_L$.
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}
    \caption{Full rebuild of the AMG hierarchy}
    \begin{algorithmic}[1]
        \FOR{all time steps}
            \IF{AMG hierarchy has to be rebuilt}
                \STATE Rebuild AMG hierarchy using the current system matrix
            \ENDIF
            \STATE Solve the current system using the latest AMG hierarchy
        \ENDFOR
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}
    \caption{Partial rebuild of the AMG hierarchy}
    \begin{algorithmic}[1]
        \FOR{all time steps}
            \IF{AMG hierarchy has to be rebuilt}
                \STATE Rebuild AMG hierarchy using the current system matrix
            \ELSE
                \STATE \emph{Update the latest AMG hierarchy:}
                \FOR{all levels $i$}
                    \STATE $A_{i+1} \leftarrow R_i A_i P_i$
                    \STATE $S_{i} \leftarrow S(A_i)$
                \ENDFOR
                \STATE Construct a direct solver for the coarsest system $A_L$.
            \ENDIF
            \STATE Solve the current system using the latest AMG hierarchy
        \ENDFOR
    \end{algorithmic}
\end{algorithm}

Note that in order to construct the next level in the AMG hierarchy, one only
needs to define transfer operators $P$ and $R$. A common choice for the
restriction operator $R$ is the transpose of the prolongation operator:
$R=P^T$.  In general, the prolongation and restriction operators depend not
only on the non-zero pattern of the system matrix, but also on its specific
values.

\section{Numerical experiments}

\begin{table}
    \caption{Relative cost of the setup operations from \Cref{alg:setup}}
    \centering
    \begin{tabular}{l|rr}
        Step & Small system & Large system \\
        \hline
        Transfer operators $P_i$ and $R_i$        & 48\% & 21\% \\
        Galerkin operator $A_{i+1} = R_i A_i P_i$ & 29\% & 24\% \\
        Smoother $S_i$                            &  3\% &  4\% \\
        Direct solver for the coarsest system     &  1\% &  0\% \\
    \end{tabular}
\end{table}

\begin{table}
    \caption{Cost savings for different reuse strategies}
    \centering
    \begin{tabularx}{\textwidth}{l|YYYYYY}
        Strategy & Setup (s) & Solve (s) & Rebuilds
        & Average iterations & Total \newline speedup (\%)
        & Setup \newline speedup (\%) \\
        \hline
        & \multicolumn{6}{c}{Convection, OpenMP} \\
        No reuse      & 1.145 & 2.780 & 49 & 5.0 &      &         \\
        Full reuse    & 0.026 & 3.186 & 1  & 5.5 & 22\% & 4~303\% \\
        Partial reuse & 0.703 & 2.769 & 5  & 5.0 & 13\% & 63\%    \\
        \hline
        & \multicolumn{6}{c}{Convection, CUDA} \\
        No reuse      & 1.890 & 0.781 & 49 & 5.0 &       &         \\
        Full reuse    & 0.039 & 0.897 & 1  & 5.5 & 185\% & 4~746\% \\
        Partial reuse & 1.284 & 0.781 & 5  & 5.0 & 29\%  & 47\%    \\
        \hline
        & \multicolumn{6}{c}{Redistancing, OpenMP} \\
        No reuse      & 1.246 & 9.508  & 49 & 15.7 &      &       \\
        Full reuse    & 0.245 & 11.324 & 9  & 18.1 & -7\% & 408\% \\
        Partial reuse & 0.749 & 9.308  & 5  & 15.6 & 7\%  & 66\%  \\
        \hline
        & \multicolumn{6}{c}{Redistancing, CUDA} \\
        No reuse      & 1.904 & 2.636 & 49 & 15.7 &      &       \\
        Full reuse    & 0.355 & 3.049 & 9  & 18.0 & 33\% & 436\% \\
        Partial reuse & 1.340 & 2.613 & 5  & 15.6 & 15\% & 42\%  \\
        \hline
        & \multicolumn{6}{c}{Navier-Stokes, OpenMP} \\
        No reuse      & 7.926 &  71.052 & 49 & 16.7 &       &       \\
        Full reuse    & 3.859 & 239.322 & 25 & 45.6 & -68\% & 105\% \\
        Partial reuse & 6.011 &  71.763 &  5 & 16.9 &   2\% &  32\% \\
        \hline
        & \multicolumn{6}{c}{Navier-Stokes, CUDA} \\
        No reuse      & 13.789 & 21.398 & 49 & 16.7 &       &       \\
        Full reuse    &  6.863 & 59.200 & 25 & 46.1 & -47\% & 101\% \\
        Partial reuse & 11.209 & 21.597 &  5 & 16.9 &   7\% &  23\% \\
    \end{tabularx}
\end{table}

\section{Conclusion}

\bibliographystyle{spmpsci}
\bibliography{ref}

\end{document}
